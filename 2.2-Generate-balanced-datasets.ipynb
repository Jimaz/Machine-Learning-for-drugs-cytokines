{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate ballanced datasets using sampling\n",
    "\n",
    "This step is used only if the dataset is not ballanced (each class has a different number of examples). Two sampling methods will be used:\n",
    "- down-sampling: randomly cut the examples from the majority class until both classes will have the same number of examples (ballanced dataset);\n",
    "- up-sampling: create new examples to complete the minority up to the majority examples.\n",
    "\n",
    "We will read the entire dataset and ballance it. After that, with other scripts, we will apply the same spliting steps before ML step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A CSV files will be create for each type of ballancing\n",
    "WorkingFolder = './datasets/'\n",
    "sOrigDataSet  = 'ds_MA.csv' # unballanced dataset\n",
    "\n",
    "seed = 0          # for reproductibility\n",
    "outVar = 'Lij'    # output variable\n",
    "\n",
    "ballancePrefix = ['downsampl.','upsampl.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by reading the unballenced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Reading source dataset: ds_MA.csv ...\n",
      "Columns: 1519 | Rows: 12766\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('-> Reading source dataset:',sOrigDataSet,'...')\n",
    "df = pd.read_csv(os.path.join(WorkingFolder, sOrigDataSet))\n",
    "print('Columns:',len(df.columns),'| Rows:',len(df))\n",
    "print('Done')\n",
    "\n",
    "X = df.drop(outVar, axis=1).values # get values of features\n",
    "y = df[outVar].values              # get output values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create functions for each type of sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling\n",
    "def UnderSamplingRnd(X,Y):\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    \n",
    "    rus = RandomUnderSampler(return_indices=True, random_state=seed)\n",
    "    X_rus, y_rus, id_rus = rus.fit_sample(X, Y)\n",
    "    return (X_rus, y_rus, id_rus) # return new X, Y and removed indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling\n",
    "def UpSamplingSMOTE(X,Y):\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "\n",
    "    smote = SMOTE(ratio='minority', random_state=seed)\n",
    "    X_sm, y_sm = smote.fit_sample(X, Y)\n",
    "    return (X_sm, y_sm) # return new X, Y for the ballanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Random Undersampling ...\n",
      "Removed indexes: [ 2176  6438  1682 ... 12703 12705 12735]\n",
      "Checking: Class 1 =  3370 Class 0 =  3370\n",
      "New shape of inputs =  (6740, 1518)\n",
      "-->> Saving undersampled dataset ./datasets/downsampl.ds_MA.csv ...\n",
      "Done!\n",
      "\n",
      "--> SMOTE updampling ...\n",
      "Checking: Class 1 =  9396 Class 0 =  9396\n",
      "New shape of inputs =  (18792, 1518)\n",
      "-->> Saving undersampled dataset ./datasets/upsampl.ds_MA.csv ...\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sampling transformation of the full dataset\n",
    "# ballancePrefix = ['upsampl.', 'downsampl.']\n",
    "\n",
    "for pref in ballancePrefix:\n",
    "    if 'downsampl.' in pref:\n",
    "        # apply random undersampling\n",
    "        print('--> Random Undersampling ...')\n",
    "        newX, newY, remIndexes = UnderSamplingRnd(X,y)\n",
    "        print('Removed indexes:', remIndexes)\n",
    "\n",
    "    if 'upsampl.' in pref:\n",
    "        ## do SMOTE up-smapling\n",
    "        print('--> SMOTE updampling ...')\n",
    "        newX, newY = UpSamplingSMOTE(X,y)\n",
    "        \n",
    "\n",
    "    # Class counts checks\n",
    "    print('Checking: Class 1 = ', sum(newY), 'Class 0 = ', len(newY) - sum(newY))\n",
    "    print('New shape of inputs = ', newX.shape)\n",
    "        \n",
    "    # create a dataframe to save the new file\n",
    "    df_ballanced = pd.DataFrame(data = newX, columns = df.drop(outVar, axis=1).columns) # add inputs\n",
    "    df_ballanced[outVar] = newY # add output var\n",
    "\n",
    "    # Save transformed file\n",
    "    \n",
    "    newFile = os.path.join(WorkingFolder, pref+sOrigDataSet)\n",
    "    print('-->> Saving undersampled dataset',newFile,'...')\n",
    "    df_ballanced.to_csv(newFile,index=False)\n",
    "    print('Done!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ballanced datasets could be used as input for Machine Learning scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
